{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import numpy\n",
    "import pandas\n",
    "import tensorflow\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dust</th>\n",
       "      <th>mq135</th>\n",
       "      <th>mq7</th>\n",
       "      <th>temperature</th>\n",
       "      <th>voc</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21</td>\n",
       "      <td>5006</td>\n",
       "      <td>3357</td>\n",
       "      <td>28.55</td>\n",
       "      <td>139</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25</td>\n",
       "      <td>5012</td>\n",
       "      <td>3356</td>\n",
       "      <td>28.55</td>\n",
       "      <td>138</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18</td>\n",
       "      <td>5009</td>\n",
       "      <td>3357</td>\n",
       "      <td>28.55</td>\n",
       "      <td>139</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26</td>\n",
       "      <td>5002</td>\n",
       "      <td>3352</td>\n",
       "      <td>28.56</td>\n",
       "      <td>139</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23</td>\n",
       "      <td>4997</td>\n",
       "      <td>3347</td>\n",
       "      <td>28.54</td>\n",
       "      <td>127</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dust  mq135   mq7  temperature  voc   label\n",
       "0    21   5006  3357        28.55  139  normal\n",
       "1    25   5012  3356        28.55  138  normal\n",
       "2    18   5009  3357        28.55  139  normal\n",
       "3    26   5002  3352        28.56  139  normal\n",
       "4    23   4997  3347        28.54  127  normal"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_file = 'sensor_data_labeled.csv'\n",
    "df = pandas.read_csv(csv_file)\n",
    "\n",
    "df = df.drop(columns=['datetime', 'epoch', 'humidity', 'pressure'])\n",
    "df['voc'] = pandas.to_numeric(df['voc'], errors='coerce')\n",
    "df = df.dropna(subset=['voc'])\n",
    "df['voc'] = df['voc'].astype(int)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['dust', 'mq135', 'mq7', 'temperature', 'voc']].values\n",
    "\n",
    "y_labels = df['label'].values\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "y_encoded = encoder.fit_transform(y_labels)\n",
    "y_categorical = to_categorical(y_encoded)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5999\n",
      "[1. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(len(y_categorical))\n",
    "print(y_categorical[2600])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['aktivitas','kimia','makanminum', 'normal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\atmatech\\Documents\\python_pred_esp32\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7703 - loss: 0.6541 - val_accuracy: 0.4496 - val_loss: 2.4608\n",
      "Epoch 2/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9022 - loss: 0.2981 - val_accuracy: 0.4496 - val_loss: 3.6231\n",
      "Epoch 3/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8980 - loss: 0.2871 - val_accuracy: 0.4442 - val_loss: 4.2574\n",
      "Epoch 4/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9040 - loss: 0.2815 - val_accuracy: 0.4483 - val_loss: 4.5684\n",
      "Epoch 5/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9028 - loss: 0.2776 - val_accuracy: 0.4467 - val_loss: 4.8081\n",
      "Epoch 6/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9149 - loss: 0.2582 - val_accuracy: 0.4458 - val_loss: 4.9555\n",
      "Epoch 7/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9148 - loss: 0.2464 - val_accuracy: 0.4492 - val_loss: 4.6912\n",
      "Epoch 8/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9287 - loss: 0.2077 - val_accuracy: 0.4467 - val_loss: 5.5997\n",
      "Epoch 9/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9271 - loss: 0.2434 - val_accuracy: 0.4483 - val_loss: 5.5477\n",
      "Epoch 10/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9320 - loss: 0.2317 - val_accuracy: 0.4421 - val_loss: 6.4972\n",
      "Epoch 11/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9270 - loss: 0.2045 - val_accuracy: 0.4425 - val_loss: 6.7056\n",
      "Epoch 12/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9227 - loss: 0.2168 - val_accuracy: 0.4346 - val_loss: 8.8777\n",
      "Epoch 13/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9154 - loss: 0.2349 - val_accuracy: 0.4442 - val_loss: 7.7592\n",
      "Epoch 14/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9351 - loss: 0.1830 - val_accuracy: 0.4471 - val_loss: 6.6801\n",
      "Epoch 15/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9266 - loss: 0.2234 - val_accuracy: 0.4342 - val_loss: 10.2625\n",
      "Epoch 16/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9366 - loss: 0.2054 - val_accuracy: 0.4458 - val_loss: 7.4191\n",
      "Epoch 17/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9263 - loss: 0.2646 - val_accuracy: 0.4417 - val_loss: 7.7772\n",
      "Epoch 18/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9373 - loss: 0.2203 - val_accuracy: 0.4387 - val_loss: 7.6258\n",
      "Epoch 19/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9218 - loss: 0.2192 - val_accuracy: 0.4329 - val_loss: 7.0402\n",
      "Epoch 20/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9373 - loss: 0.1893 - val_accuracy: 0.3750 - val_loss: 11.7143\n",
      "Epoch 21/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9337 - loss: 0.2170 - val_accuracy: 0.3750 - val_loss: 11.0192\n",
      "Epoch 22/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9317 - loss: 0.2204 - val_accuracy: 0.3750 - val_loss: 10.8777\n",
      "Epoch 23/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9281 - loss: 0.2043 - val_accuracy: 0.4308 - val_loss: 8.8327\n",
      "Epoch 24/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9154 - loss: 0.2475 - val_accuracy: 0.4379 - val_loss: 8.6991\n",
      "Epoch 25/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9269 - loss: 0.2283 - val_accuracy: 0.4288 - val_loss: 9.6532\n",
      "Epoch 26/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9368 - loss: 0.2236 - val_accuracy: 0.4029 - val_loss: 9.0807\n",
      "Epoch 27/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9329 - loss: 0.1925 - val_accuracy: 0.3750 - val_loss: 8.3033\n",
      "Epoch 28/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9307 - loss: 0.2168 - val_accuracy: 0.4342 - val_loss: 7.5755\n",
      "Epoch 29/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9433 - loss: 0.1945 - val_accuracy: 0.4367 - val_loss: 9.1420\n",
      "Epoch 30/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9338 - loss: 0.2171 - val_accuracy: 0.4354 - val_loss: 7.6264\n",
      "Epoch 31/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9307 - loss: 0.2356 - val_accuracy: 0.3800 - val_loss: 10.0505\n",
      "Epoch 32/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9364 - loss: 0.1978 - val_accuracy: 0.3750 - val_loss: 15.0927\n",
      "Epoch 33/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9298 - loss: 0.2171 - val_accuracy: 0.3775 - val_loss: 11.9104\n",
      "Epoch 34/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9414 - loss: 0.1878 - val_accuracy: 0.3808 - val_loss: 9.3049\n",
      "Epoch 35/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9239 - loss: 0.2209 - val_accuracy: 0.3825 - val_loss: 8.7636\n",
      "Epoch 36/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9367 - loss: 0.2065 - val_accuracy: 0.3812 - val_loss: 9.2854\n",
      "Epoch 37/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9326 - loss: 0.2117 - val_accuracy: 0.3812 - val_loss: 11.6533\n",
      "Epoch 38/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9304 - loss: 0.2380 - val_accuracy: 0.3775 - val_loss: 15.6582\n",
      "Epoch 39/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9255 - loss: 0.2459 - val_accuracy: 0.3775 - val_loss: 12.2023\n",
      "Epoch 40/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9172 - loss: 0.2551 - val_accuracy: 0.3792 - val_loss: 11.9244\n",
      "Epoch 41/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9267 - loss: 0.2255 - val_accuracy: 0.3771 - val_loss: 11.9095\n",
      "Epoch 42/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9060 - loss: 0.2730 - val_accuracy: 0.3808 - val_loss: 10.6019\n",
      "Epoch 43/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9187 - loss: 0.2467 - val_accuracy: 0.3817 - val_loss: 7.6494\n",
      "Epoch 44/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9205 - loss: 0.2282 - val_accuracy: 0.3750 - val_loss: 14.0543\n",
      "Epoch 45/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9154 - loss: 0.2449 - val_accuracy: 0.3775 - val_loss: 11.1070\n",
      "Epoch 46/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9145 - loss: 0.2390 - val_accuracy: 0.3800 - val_loss: 11.2799\n",
      "Epoch 47/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9254 - loss: 0.2188 - val_accuracy: 0.3783 - val_loss: 10.6417\n",
      "Epoch 48/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8979 - loss: 0.2755 - val_accuracy: 0.3750 - val_loss: 18.1726\n",
      "Epoch 49/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9233 - loss: 0.2338 - val_accuracy: 0.3750 - val_loss: 16.1929\n",
      "Epoch 50/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9336 - loss: 0.2059 - val_accuracy: 0.3750 - val_loss: 15.9224\n",
      "Epoch 51/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9178 - loss: 0.2485 - val_accuracy: 0.3758 - val_loss: 11.9336\n",
      "Epoch 52/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9237 - loss: 0.2318 - val_accuracy: 0.3750 - val_loss: 16.2704\n",
      "Epoch 53/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9241 - loss: 0.2334 - val_accuracy: 0.3750 - val_loss: 13.4447\n",
      "Epoch 54/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9239 - loss: 0.2259 - val_accuracy: 0.3750 - val_loss: 15.2962\n",
      "Epoch 55/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9241 - loss: 0.2263 - val_accuracy: 0.3750 - val_loss: 14.3352\n",
      "Epoch 56/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9362 - loss: 0.2152 - val_accuracy: 0.3750 - val_loss: 14.8169\n",
      "Epoch 57/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9341 - loss: 0.2297 - val_accuracy: 0.3750 - val_loss: 16.7692\n",
      "Epoch 58/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9238 - loss: 0.2526 - val_accuracy: 0.3750 - val_loss: 25.6139\n",
      "Epoch 59/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9119 - loss: 0.2414 - val_accuracy: 0.3750 - val_loss: 24.2429\n",
      "Epoch 60/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9215 - loss: 0.2304 - val_accuracy: 0.3750 - val_loss: 25.0343\n",
      "Epoch 61/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9269 - loss: 0.2063 - val_accuracy: 0.3750 - val_loss: 20.2117\n",
      "Epoch 62/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9478 - loss: 0.1762 - val_accuracy: 0.3750 - val_loss: 22.9235\n",
      "Epoch 63/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9173 - loss: 0.2534 - val_accuracy: 0.3750 - val_loss: 21.1041\n",
      "Epoch 64/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9255 - loss: 0.2253 - val_accuracy: 0.3750 - val_loss: 19.1131\n",
      "Epoch 65/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9340 - loss: 0.2156 - val_accuracy: 0.3750 - val_loss: 19.8499\n",
      "Epoch 66/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9305 - loss: 0.2171 - val_accuracy: 0.3750 - val_loss: 20.8078\n",
      "Epoch 67/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9082 - loss: 0.2456 - val_accuracy: 0.3750 - val_loss: 22.9163\n",
      "Epoch 68/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9374 - loss: 0.2288 - val_accuracy: 0.3750 - val_loss: 19.2950\n",
      "Epoch 69/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9142 - loss: 0.2417 - val_accuracy: 0.3750 - val_loss: 18.1512\n",
      "Epoch 70/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9301 - loss: 0.2405 - val_accuracy: 0.3750 - val_loss: 18.7698\n",
      "Epoch 71/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9133 - loss: 0.2660 - val_accuracy: 0.3750 - val_loss: 17.4859\n",
      "Epoch 72/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9263 - loss: 0.2316 - val_accuracy: 0.3750 - val_loss: 17.9864\n",
      "Epoch 73/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9216 - loss: 0.2317 - val_accuracy: 0.3750 - val_loss: 18.5629\n",
      "Epoch 74/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9156 - loss: 0.2634 - val_accuracy: 0.3750 - val_loss: 17.8098\n",
      "Epoch 75/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9181 - loss: 0.2402 - val_accuracy: 0.3750 - val_loss: 15.6890\n",
      "Epoch 76/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8987 - loss: 0.2688 - val_accuracy: 0.3750 - val_loss: 17.5321\n",
      "Epoch 77/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9223 - loss: 0.2443 - val_accuracy: 0.3750 - val_loss: 21.5534\n",
      "Epoch 78/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9062 - loss: 0.2694 - val_accuracy: 0.3750 - val_loss: 20.2747\n",
      "Epoch 79/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9242 - loss: 0.2385 - val_accuracy: 0.3750 - val_loss: 16.4554\n",
      "Epoch 80/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9156 - loss: 0.2544 - val_accuracy: 0.3750 - val_loss: 17.0443\n",
      "Epoch 81/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9258 - loss: 0.2340 - val_accuracy: 0.3750 - val_loss: 21.4477\n",
      "Epoch 82/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9223 - loss: 0.2228 - val_accuracy: 0.3750 - val_loss: 18.8125\n",
      "Epoch 83/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9188 - loss: 0.2262 - val_accuracy: 0.3750 - val_loss: 15.3381\n",
      "Epoch 84/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9307 - loss: 0.2295 - val_accuracy: 0.3750 - val_loss: 18.0580\n",
      "Epoch 85/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9290 - loss: 0.2205 - val_accuracy: 0.3750 - val_loss: 18.2559\n",
      "Epoch 86/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9093 - loss: 0.2854 - val_accuracy: 0.3750 - val_loss: 20.1946\n",
      "Epoch 87/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9237 - loss: 0.2442 - val_accuracy: 0.3750 - val_loss: 20.2124\n",
      "Epoch 88/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9175 - loss: 0.2583 - val_accuracy: 0.3750 - val_loss: 19.5958\n",
      "Epoch 89/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9183 - loss: 0.2411 - val_accuracy: 0.3750 - val_loss: 18.7094\n",
      "Epoch 90/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9228 - loss: 0.2342 - val_accuracy: 0.3750 - val_loss: 19.7923\n",
      "Epoch 91/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9208 - loss: 0.2351 - val_accuracy: 0.3750 - val_loss: 22.7403\n",
      "Epoch 92/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9308 - loss: 0.2122 - val_accuracy: 0.3750 - val_loss: 19.3084\n",
      "Epoch 93/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9329 - loss: 0.1996 - val_accuracy: 0.3750 - val_loss: 21.7491\n",
      "Epoch 94/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9201 - loss: 0.2254 - val_accuracy: 0.3750 - val_loss: 24.4359\n",
      "Epoch 95/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9348 - loss: 0.1973 - val_accuracy: 0.3750 - val_loss: 21.8355\n",
      "Epoch 96/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9225 - loss: 0.2266 - val_accuracy: 0.3750 - val_loss: 22.2462\n",
      "Epoch 97/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9171 - loss: 0.2418 - val_accuracy: 0.3750 - val_loss: 22.2880\n",
      "Epoch 98/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9333 - loss: 0.1942 - val_accuracy: 0.3750 - val_loss: 22.8110\n",
      "Epoch 99/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9356 - loss: 0.2161 - val_accuracy: 0.3750 - val_loss: 20.5758\n",
      "Epoch 100/100\n",
      "\u001b[1m900/900\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9135 - loss: 0.2344 - val_accuracy: 0.3750 - val_loss: 22.7565\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Dense(64, input_shape=(5,), activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    Dense(32, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.2),\n",
    "    \n",
    "    Dense(4, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X, y_categorical, epochs=100, batch_size=4, verbose=1, validation_split=0.4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], 'b', label='Training accuracy')\n",
    "plt.plot(history.history['val_accuracy'], 'r', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], 'b', label='Training loss')\n",
    "plt.plot(history.history['val_loss'], 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save('model_feedforward.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  24.   5949.   4714.     28.77   94.  ]\n",
      "kimia\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "Prediksi kelas: aktivitas >> [np.int64(0)]\n"
     ]
    }
   ],
   "source": [
    "id = 4500\n",
    "print(X[id])\n",
    "print(y_labels[id])\n",
    "\n",
    "data_to_predict = numpy.array([[  24. ,  5949.  , 4714.,28.77, 94.]]) \n",
    "y_pred = model.predict(data_to_predict)\n",
    "\n",
    "predicted_class = numpy.argmax(y_pred, axis=1)\n",
    "print(f\"Prediksi kelas: {categories[predicted_class[0]]} >> {[predicted_class[0]]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 9.1409, Accuracy: 0.7496\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X, y_categorical, verbose=0)\n",
    "print(f\"Loss: {loss:.4f}, Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\atmatech\\AppData\\Local\\Temp\\tmpmyopqw8p\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\atmatech\\AppData\\Local\\Temp\\tmpmyopqw8p\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at 'C:\\Users\\atmatech\\AppData\\Local\\Temp\\tmpmyopqw8p'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 5), dtype=tf.float32, name='keras_tensor_125')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 4), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  2102102466704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2102102469776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2102102470160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2102102469392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2102102469200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2102102469968: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2102102470928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2102102472080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2102102472464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2102102470544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2102102471312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2102102472272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2102102473232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2102102474192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    }
   ],
   "source": [
    "converter = tensorflow.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open('model_feedforward.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
